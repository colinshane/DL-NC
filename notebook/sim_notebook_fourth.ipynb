{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tensorflow tutorials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "\n",
    "input1 = tf.placeholder(tf.float32)\n",
    "input2 = tf.placeholder(tf.float32)\n",
    "output = tf.multiply(input1, input2)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(output, feed_dict={input1: [7.], input2: [2.]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "var = tf.Variable(0)    # our first variable in the \"global_variable\" set\n",
    "\n",
    "add_operation = tf.add(var, 1)\n",
    "update_operation = tf.assign(var, add_operation)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # once define variables, you have to initialize them by doing this\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for _ in range(3):\n",
    "        sess.run(update_operation)\n",
    "        print(sess.run(var))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "m1 = tf.constant([[2, 2]])\n",
    "m2 = tf.constant([[3],\n",
    "                  [3]])\n",
    "dot_operation = tf.matmul(m1, m2)\n",
    "\n",
    "print(dot_operation)  # wrong! no result\n",
    "\n",
    "# method1 use session\n",
    "sess = tf.Session()\n",
    "result = sess.run(dot_operation)\n",
    "print(result)\n",
    "sess.close()\n",
    "\n",
    "# method2 use session\n",
    "with tf.Session() as sess:\n",
    "    result_ = sess.run(dot_operation)\n",
    "    print(result_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "tf.set_random_seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "# fake data\n",
    "x = np.linspace(-1, 1, 100)[:, np.newaxis]          # shape (100, 1)\n",
    "noise = np.random.normal(0, 0.1, size=x.shape)\n",
    "y = np.power(x, 2) + noise                          # shape (100, 1) + some noise\n",
    "\n",
    "# plot data\n",
    "plt.scatter(x, y)\n",
    "plt.show()\n",
    "\n",
    "tf_x = tf.placeholder(tf.float32, x.shape)     # input x\n",
    "tf_y = tf.placeholder(tf.float32, y.shape)     # input y\n",
    "\n",
    "# neural network layers\n",
    "l1 = tf.layers.dense(tf_x, 10, tf.nn.relu)          # hidden layer\n",
    "output = tf.layers.dense(l1, 1)                     # output layer\n",
    "\n",
    "loss = tf.losses.mean_squared_error(tf_y, output)   # compute cost\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.5)\n",
    "train_op = optimizer.minimize(loss)\n",
    "\n",
    "sess = tf.Session()                                 # control training and others\n",
    "sess.run(tf.global_variables_initializer())         # initialize var in graph\n",
    "\n",
    "plt.ion()   # something about plotting\n",
    "\n",
    "for step in range(100):\n",
    "    # train and net output\n",
    "    _, l, pred = sess.run([train_op, loss, output], {tf_x: x, tf_y: y})\n",
    "    if step % 5 == 0:\n",
    "        # plot and show learning process\n",
    "        plt.cla()\n",
    "        plt.scatter(x, y)\n",
    "        plt.plot(x, pred, 'r-', lw=5)\n",
    "        plt.text(0.5, 0, 'Loss=%.4f' % l, fontdict={'size': 20, 'color': 'red'})\n",
    "        plt.pause(0.1)\n",
    "\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def add_layer(inputs, in_size, out_size, activation_function=None):\n",
    "    Weights = tf.Variable(tf.random_normal([in_size, out_size]))\n",
    "    biases = tf.Variable(tf.zeros([1, out_size]) + 0.1)\n",
    "    Wx_plus_b = tf.matmul(inputs, Weights) + biases\n",
    "    if activation_function is None:\n",
    "        outputs = Wx_plus_b\n",
    "    else:\n",
    "        outputs = activation_function(Wx_plus_b)\n",
    "    return outputs\n",
    "\n",
    "# Make up some real data\n",
    "x_data = np.linspace(-1, 1, 300)[:, np.newaxis]\n",
    "noise = np.random.normal(0, 0.05, x_data.shape)\n",
    "y_data = np.square(x_data) - 0.5 + noise\n",
    "\n",
    "##plt.scatter(x_data, y_data)\n",
    "##plt.show()\n",
    "\n",
    "# define placeholder for inputs to network\n",
    "xs = tf.placeholder(tf.float32, [None, 1])\n",
    "ys = tf.placeholder(tf.float32, [None, 1])\n",
    "# add hidden layer\n",
    "l1 = add_layer(xs, 1, 10, activation_function=tf.nn.relu)\n",
    "# add output layer\n",
    "prediction = add_layer(l1, 10, 1, activation_function=None)\n",
    "\n",
    "# the error between prediction and real data\n",
    "loss = tf.reduce_mean(tf.reduce_sum(tf.square(ys-prediction), reduction_indices=[1]))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.1).minimize(loss)\n",
    "# important step\n",
    "sess = tf.Session()\n",
    "# tf.initialize_all_variables() no long valid from\n",
    "# 2017-03-02 if using tensorflow >= 0.12\n",
    "if int((tf.__version__).split('.')[1]) < 12 and int((tf.__version__).split('.')[0]) < 1:\n",
    "    init = tf.initialize_all_variables()\n",
    "else:\n",
    "    init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "# plot the real data\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.scatter(x_data, y_data)\n",
    "plt.ion()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "for i in range(1000):\n",
    "    # training\n",
    "    sess.run(train_step, feed_dict={xs: x_data, ys: y_data})\n",
    "    if i % 50 == 0:\n",
    "        # to visualize the result and improvement\n",
    "        try:\n",
    "            ax.lines.remove(lines[0])\n",
    "        except Exception:\n",
    "            pass\n",
    "        prediction_value = sess.run(prediction, feed_dict={xs: x_data})\n",
    "        # plot the prediction\n",
    "        lines = ax.plot(x_data, prediction_value, 'r-', lw=5)\n",
    "        plt.pause(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "tf.set_random_seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "# fake data\n",
    "n_data = np.ones((100, 2))\n",
    "x0 = np.random.normal(2*n_data, 1)      # class0 x shape=(100, 2)\n",
    "y0 = np.zeros(100)                      # class0 y shape=(100, 1)\n",
    "x1 = np.random.normal(-2*n_data, 1)     # class1 x shape=(100, 2)\n",
    "y1 = np.ones(100)                       # class1 y shape=(100, 1)\n",
    "x = np.vstack((x0, x1))  # shape (200, 2) + some noise\n",
    "y = np.hstack((y0, y1))  # shape (200, )\n",
    "\n",
    "# plot data\n",
    "plt.scatter(x[:, 0], x[:, 1], c=y, s=100, lw=0, cmap='RdYlGn')\n",
    "plt.show()\n",
    "\n",
    "tf_x = tf.placeholder(tf.float32, x.shape)     # input x\n",
    "tf_y = tf.placeholder(tf.int32, y.shape)     # input y\n",
    "\n",
    "# neural network layers\n",
    "l1 = tf.layers.dense(tf_x, 10, tf.nn.relu)          # hidden layer\n",
    "output = tf.layers.dense(l1, 2)                     # output layer\n",
    "\n",
    "loss = tf.losses.sparse_softmax_cross_entropy(labels=tf_y, logits=output)           # compute cost\n",
    "accuracy = tf.metrics.accuracy(          # return (acc, update_op), and create 2 local variables\n",
    "    labels=tf.squeeze(tf_y), predictions=tf.argmax(output, axis=1),)[1]\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.05)\n",
    "train_op = optimizer.minimize(loss)\n",
    "\n",
    "sess = tf.Session()                                                                 # control training and others\n",
    "init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "sess.run(init_op)     # initialize var in graph\n",
    "\n",
    "plt.ion()   # something about plotting\n",
    "for step in range(100):\n",
    "    # train and net output\n",
    "    _, acc, pred = sess.run([train_op, accuracy, output], {tf_x: x, tf_y: y})\n",
    "    if step % 2 == 0:\n",
    "        # plot and show learning process\n",
    "        plt.cla()\n",
    "        plt.scatter(x[:, 0], x[:, 1], c=pred.argmax(1), s=100, lw=0, cmap='RdYlGn')\n",
    "        plt.text(1.5, -4, 'Accuracy=%.2f' % acc, fontdict={'size': 20, 'color': 'red'})\n",
    "        plt.pause(0.1)\n",
    "\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "tf.set_random_seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "LR = 0.01\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# fake data\n",
    "x = np.linspace(-1, 1, 100)[:, np.newaxis]          # shape (100, 1)\n",
    "noise = np.random.normal(0, 0.1, size=x.shape)\n",
    "y = np.power(x, 2) + noise                          # shape (100, 1) + some noise\n",
    "\n",
    "# plot dataset\n",
    "plt.scatter(x, y)\n",
    "plt.show()\n",
    "\n",
    "# default network\n",
    "class Net:\n",
    "    def __init__(self, opt, **kwargs):\n",
    "        self.x = tf.placeholder(tf.float32, [None, 1])\n",
    "        self.y = tf.placeholder(tf.float32, [None, 1])\n",
    "        l = tf.layers.dense(self.x, 20, tf.nn.relu)\n",
    "        out = tf.layers.dense(l, 1)\n",
    "        self.loss = tf.losses.mean_squared_error(self.y, out)\n",
    "        self.train = opt(LR, **kwargs).minimize(self.loss)\n",
    "\n",
    "# different nets\n",
    "net_SGD         = Net(tf.train.GradientDescentOptimizer)\n",
    "net_Momentum    = Net(tf.train.MomentumOptimizer, momentum=0.9)\n",
    "net_RMSprop     = Net(tf.train.RMSPropOptimizer)\n",
    "net_Adam        = Net(tf.train.AdamOptimizer)\n",
    "nets = [net_SGD, net_Momentum, net_RMSprop, net_Adam]\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "losses_his = [[], [], [], []]   # record loss\n",
    "\n",
    "# training\n",
    "for step in range(300):          # for each training step\n",
    "    index = np.random.randint(0, x.shape[0], BATCH_SIZE)\n",
    "    b_x = x[index]\n",
    "    b_y = y[index]\n",
    "\n",
    "    for net, l_his in zip(nets, losses_his):\n",
    "        _, l = sess.run([net.train, net.loss], {net.x: b_x, net.y: b_y})\n",
    "        l_his.append(l)     # loss recoder\n",
    "\n",
    "# plot loss history\n",
    "labels = ['SGD', 'Momentum', 'RMSprop', 'Adam']\n",
    "for i, l_his in enumerate(losses_his):\n",
    "    plt.plot(l_his, label=labels[i])\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Loss')\n",
    "plt.ylim((0, 0.2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def add_layer(inputs, in_size, out_size, n_layer, activation_function=None):\n",
    "    # add one more layer and return the output of this layer\n",
    "    layer_name = 'layer%s' % n_layer\n",
    "    with tf.name_scope(layer_name):\n",
    "        with tf.name_scope('weights'):\n",
    "            Weights = tf.Variable(tf.random_normal([in_size, out_size]), name='W')\n",
    "            tf.summary.histogram(layer_name + '/weights', Weights)\n",
    "        with tf.name_scope('biases'):\n",
    "            biases = tf.Variable(tf.zeros([1, out_size]) + 0.1, name='b')\n",
    "            tf.summary.histogram(layer_name + '/biases', biases)\n",
    "        with tf.name_scope('Wx_plus_b'):\n",
    "            Wx_plus_b = tf.add(tf.matmul(inputs, Weights), biases)\n",
    "        if activation_function is None:\n",
    "            outputs = Wx_plus_b\n",
    "        else:\n",
    "            outputs = activation_function(Wx_plus_b, )\n",
    "        tf.summary.histogram(layer_name + '/outputs', outputs)\n",
    "    return outputs\n",
    "\n",
    "\n",
    "# Make up some real data\n",
    "x_data = np.linspace(-1, 1, 300)[:, np.newaxis]\n",
    "noise = np.random.normal(0, 0.05, x_data.shape)\n",
    "y_data = np.square(x_data) - 0.5 + noise\n",
    "\n",
    "# define placeholder for inputs to network\n",
    "with tf.name_scope('inputs'):\n",
    "    xs = tf.placeholder(tf.float32, [None, 1], name='x_input')\n",
    "    ys = tf.placeholder(tf.float32, [None, 1], name='y_input')\n",
    "\n",
    "# add hidden layer\n",
    "l1 = add_layer(xs, 1, 10, n_layer=1, activation_function=tf.nn.relu)\n",
    "# add output layer\n",
    "prediction = add_layer(l1, 10, 1, n_layer=2, activation_function=None)\n",
    "\n",
    "# the error between prediciton and real data\n",
    "with tf.name_scope('loss'):\n",
    "    loss = tf.reduce_mean(tf.reduce_sum(tf.square(ys - prediction),\n",
    "                                        reduction_indices=[1]))\n",
    "    tf.summary.scalar('loss', loss)\n",
    "\n",
    "with tf.name_scope('train'):\n",
    "    train_step = tf.train.GradientDescentOptimizer(0.1).minimize(loss)\n",
    "\n",
    "sess = tf.Session()\n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "writer = tf.summary.FileWriter(\"logs/\", sess.graph)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "for i in range(1000):\n",
    "    sess.run(train_step, feed_dict={xs: x_data, ys: y_data})\n",
    "    if i % 50 == 0:\n",
    "        result = sess.run(merged,\n",
    "                          feed_dict={xs: x_data, ys: y_data})\n",
    "        writer.add_summary(result, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "tf.set_random_seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "# fake data\n",
    "x = np.linspace(-1, 1, 100)[:, np.newaxis]          # shape (100, 1)\n",
    "noise = np.random.normal(0, 0.1, size=x.shape)\n",
    "y = np.power(x, 2) + noise                          # shape (100, 1) + some noise\n",
    "\n",
    "with tf.variable_scope('Inputs'):\n",
    "    tf_x = tf.placeholder(tf.float32, x.shape, name='x')\n",
    "    tf_y = tf.placeholder(tf.float32, y.shape, name='y')\n",
    "\n",
    "with tf.variable_scope('Net'):\n",
    "    l1 = tf.layers.dense(tf_x, 10, tf.nn.relu, name='hidden_layer')\n",
    "    output = tf.layers.dense(l1, 1, name='output_layer')\n",
    "\n",
    "    # add to histogram summary\n",
    "    tf.summary.histogram('h_out', l1)\n",
    "    tf.summary.histogram('pred', output)\n",
    "\n",
    "loss = tf.losses.mean_squared_error(tf_y, output, scope='loss')\n",
    "train_op = tf.train.GradientDescentOptimizer(learning_rate=0.5).minimize(loss)\n",
    "tf.summary.scalar('loss', loss)     # add loss to scalar summary\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "writer = tf.summary.FileWriter('logs/', sess.graph)     # write to file\n",
    "merge_op = tf.summary.merge_all()                       # operation to merge all summary\n",
    "\n",
    "for step in range(100):\n",
    "    # train and net output\n",
    "    _, result = sess.run([train_op, merge_op], {tf_x: x, tf_y: y})\n",
    "    writer.add_summary(result, step)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0/200 |train loss: 0.29639 |test loss: 0.303586\n",
      "step: 10/200 |train loss: 0.111375 |test loss: 0.0977778\n",
      "step: 20/200 |train loss: 0.060009 |test loss: 0.07659\n",
      "step: 30/200 |train loss: 0.078113 |test loss: 0.063193\n",
      "step: 40/200 |train loss: 0.0648966 |test loss: 0.0548918\n",
      "step: 50/200 |train loss: 0.0439152 |test loss: 0.0474642\n",
      "step: 60/200 |train loss: 0.037922 |test loss: 0.0424611\n",
      "step: 70/200 |train loss: 0.0383202 |test loss: 0.0366488\n",
      "Finish the last epoch.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.contrib.data import Dataset\n",
    "\n",
    "\n",
    "# load your data or create your data in here\n",
    "npx = np.random.uniform(-1, 1, (1000, 1))                           # x data\n",
    "npy = np.power(npx, 2) + np.random.normal(0, 0.1, size=npx.shape)   # y data\n",
    "npx_train, npx_test = np.split(npx, [800])                          # training and test data\n",
    "npy_train, npy_test = np.split(npy, [800])\n",
    "\n",
    "# use placeholder, later you may need different data, pass the different data into placeholder\n",
    "tfx = tf.placeholder(npx_train.dtype, npx_train.shape)\n",
    "tfy = tf.placeholder(npy_train.dtype, npy_train.shape)\n",
    "\n",
    "# create dataloader\n",
    "dataset = Dataset.from_tensor_slices((tfx, tfy))\n",
    "dataset = dataset.shuffle(buffer_size=1000)   # choose data randomly from this buffer\n",
    "dataset = dataset.batch(32)                   # batch size you will use\n",
    "dataset = dataset.repeat(3)                   # repeat for 3 epochs\n",
    "iterator = dataset.make_initializable_iterator()  # later we have to initialize this one\n",
    "\n",
    "# your network\n",
    "bx, by = iterator.get_next()                  # use batch to update\n",
    "l1 = tf.layers.dense(bx, 10, tf.nn.relu)\n",
    "out = tf.layers.dense(l1, npy.shape[1])\n",
    "loss = tf.losses.mean_squared_error(by, out)\n",
    "train = tf.train.GradientDescentOptimizer(0.1).minimize(loss)\n",
    "\n",
    "sess = tf.Session()\n",
    "# need to initialize the iterator in this case\n",
    "sess.run([iterator.initializer, tf.global_variables_initializer()], feed_dict={tfx: npx_train, tfy: npy_train})\n",
    "\n",
    "for step in range(201):\n",
    "  try:\n",
    "    _, trainl = sess.run([train, loss])                       # train\n",
    "    if step % 10 == 0:\n",
    "      testl = sess.run(loss, {bx: npx_test, by: npy_test})    # test\n",
    "      print('step: %i/200' % step, '|train loss:', trainl, '|test loss:', testl)\n",
    "  except tf.errors.OutOfRangeError:     # if training takes more than 3 epochs, training will be stopped\n",
    "    print('Finish the last epoch.')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
